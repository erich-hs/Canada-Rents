{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pytesseract"
      ],
      "metadata": {
        "id": "yQ7yvnac0cG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DcRWrBA00ge3",
        "outputId": "212bb6da-dfca-4e03-db6c-ffe18a55201e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (3,566 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting Pillow>=8.0.0\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
            "Installing collected packages: Pillow, pytesseract\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed Pillow-9.2.0 pytesseract-0.3.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcVQ1DKJiA2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a5e818-3c2a-4ab3-816a-b474b9570f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV version: 4.6.0\n",
            "PyTesseract version: 0.3.10\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pytesseract, shutil, os, cv2, re\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from statistics import mean, median, stdev\n",
        "from tabulate import tabulate\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "sns.set_theme(style = \"ticks\",\n",
        "              palette = sns.dark_palette(\"seagreen\", reverse=True))\n",
        "\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "print(f\"PyTesseract version: {pytesseract.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and output directories\n",
        "os.mkdir('data/')\n",
        "os.mkdir('output/')\n",
        "os.mkdir('output/png/')\n",
        "os.mkdir('output/csv/')"
      ],
      "metadata": {
        "id": "-oLg5PbtgVGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = glob('data/*.png')\n",
        "images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owq9YvKpB2Gy",
        "outputId": "088676a8-373f-41a4-9bb6-d701c28cd20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/Rent_Report_-_July_2020.width-720-1.png',\n",
              " 'data/Rent_Report_-_April_2020.width-720-469x1024.png',\n",
              " 'data/Rent_Report_-_April_2019.width-720-431x1024.png',\n",
              " 'data/Rent_Report_-_May_2022_.width-720.png',\n",
              " 'data/Rent_Report_-_October_2020.width-720.png',\n",
              " 'data/Rent-Report-November-2020-1-1-e1611353009250.png',\n",
              " 'data/rent_report_-_January_2022_2.width-720.png',\n",
              " 'data/Rent_Report_-_May_2020.width-720-1-439x1024.png',\n",
              " 'data/Rentals.ca_-_Rent_Report_-_January_2019.width-720-483x1024.png',\n",
              " 'data/Rent_Report_-_May_2019.width-720-431x1024.png',\n",
              " 'data/Rent_Report_-_February_2020.width-720.png',\n",
              " 'data/Rent_Report_-_August_2020.width-720.png',\n",
              " 'data/Rent_Report_-_March_2021.width-720.png',\n",
              " 'data/Rent_Report_-_February_2022_2.width-720.png',\n",
              " 'data/rent_report_-_November_2021.width-720.png',\n",
              " 'data/Rent_Report_-_December_2021.width-720.png',\n",
              " 'data/Rent_Report_Graphic__-_August_2022_2.width-720.png',\n",
              " 'data/Rent_Report_-_April_2021_1.width-720.png',\n",
              " 'data/Rent_Report_-_September_2021_1.width-720.png',\n",
              " 'data/Rent_Report_-_April_2022.width-720.png',\n",
              " 'data/Rent_Report_-_December_2019.width-720.png',\n",
              " 'data/Rent_Report_-December_2020_1.width-720.png',\n",
              " 'data/Rent_Report_-_October_2021.width-720.png',\n",
              " 'data/Rent_Report_-_June_2021_1.width-720.png',\n",
              " 'data/Rent_Report_Graphic_template_-_June_2022.width-720.png',\n",
              " 'data/Final_March_2019-rent_Report-rankings-483x1024.png',\n",
              " 'data/Rent_Report_-_May_2021_1.width-720.png',\n",
              " 'data/Rent_Report_-_June_2020.width-720.png',\n",
              " 'data/Rent_Report_-_January_2021_2.width-720.png',\n",
              " 'data/Rent_Report_-_July_2021_1.width-720.png',\n",
              " 'data/Rent_Report_-_July_2019.width-720.png',\n",
              " 'data/Rent_Report_-_March_2020.width-720-401x1024.png',\n",
              " 'data/Rent_Report_-_March_2022.width-720.png',\n",
              " 'data/Rent_Report_-_February_2021.width-720.png',\n",
              " 'data/Rent_Report_February_2019.width-720-483x1024.png',\n",
              " 'data/Rent_Report_-_June_2019.width-720.png',\n",
              " 'data/Rent_Report_Graphic__-_July_2022.width-720.png',\n",
              " 'data/Rent_Report_-_October_2019.width-720.png',\n",
              " 'data/Rent_Report_-_August_2021.width-720.png',\n",
              " 'data/Rent_Report_-_September_2020.width-720.png']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image,\n",
        "               resize = False,\n",
        "               preserve_ar = True,\n",
        "               grayscale = False,\n",
        "               gaussian_blur = False,\n",
        "               thresholding = False,\n",
        "               thresh_value = 127,\n",
        "               invert_output = False,\n",
        "               verbose = True):\n",
        "  '''\n",
        "  Preprocess image object input with:\n",
        "  image: image input file path;\n",
        "  resize: Resize to desired width and height dimensions. Takes arguments tuple\n",
        "    (width, height), single Integer as target width or false boolean. Will\n",
        "    inforce aspect ratio based on passed target width if preserve_ar argument is\n",
        "    set to True. Default = False. Default = True if resize argument is integer;\n",
        "  preserve_ar: Boolean argument to preserve original image's Aspect Ratio or\n",
        "    redefine based on 'resize' input. Default = True;\n",
        "  grayscale: OpenCV grayscaling. Takes argument boolean = True or False.\n",
        "    Default = False;\n",
        "  gaussian_blur: Smooth image input with a gaussian blurring method. Takes\n",
        "    arguments Integer kernel size or false boolean. Default = False;\n",
        "  thresholding: OpenCV simple thresholding. Takes arguments [binary, binary_inv]\n",
        "    or false boolean. Default = False;\n",
        "  thresh_value: OpenCV threshold value. Takes argument Int. Default = 127;\n",
        "  invert_output: Boolean argument to invert output binary image. Default = False;\n",
        "  '''\n",
        "  # Image load and input dimensions\n",
        "  input_file = image\n",
        "  image = cv2.imread(image)\n",
        "  input_height = int(image.shape[0])\n",
        "  input_width = int(image.shape[1])\n",
        "  aspect_ratio = input_height/input_width\n",
        "  \n",
        "  if verbose:\n",
        "    print(f\"Processing input file: {input_file}...\")\n",
        "\n",
        "  # Resizing\n",
        "  if type(resize) == int:\n",
        "    resize = (resize,)\n",
        "\n",
        "  if resize:\n",
        "    if preserve_ar:\n",
        "      image = cv2.resize(image, (resize[0], int(resize[0]*aspect_ratio)))\n",
        "    else:\n",
        "      image = cv2.resize(image, (resize[0], input_height))\n",
        "  \n",
        "  output_height = int(image.shape[0])\n",
        "  output_width = int(image.shape[1])\n",
        "\n",
        "  # Gray-scaling\n",
        "  if grayscale:\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Blurring\n",
        "  if gaussian_blur:\n",
        "    image = cv2.GaussianBlur(image, (5, 5), gaussian_blur)\n",
        "\n",
        "  # Thresholding\n",
        "  if thresholding:\n",
        "    if thresholding == \"binary\":\n",
        "      image = cv2.threshold(image, thresh_value, 255, cv2.THRESH_BINARY_INV)[1]\n",
        "    elif thresholding == \"binary_inv\":\n",
        "      image = cv2.threshold(image, thresh_value, 255, cv2.THRESH_BINARY_INV)[1]\n",
        "    else:\n",
        "      print(\"Invalid thresholding argument!\")\n",
        "  \n",
        "  # Inverting binary image\n",
        "  if invert_output:\n",
        "    image = np.invert(image)\n",
        "\n",
        "  if verbose:\n",
        "    print(f\"Image input dimensions: {(input_width, input_height)}\\n\"\\\n",
        "          f\"Image output dimensions: {(output_width, output_height)}\\n\")\n",
        "  return image"
      ],
      "metadata": {
        "id": "cveMb8ngPcCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_table(image,\n",
        "               pytesseract_config = \"--psm 4\",\n",
        "               conf_thresh = 0,\n",
        "               h_padding = 10,\n",
        "               v_padding = 10,\n",
        "               h_distance_threshold = 3,\n",
        "               v_distance_threshold = 15,\n",
        "               v_cluster_threshold = 10,\n",
        "               smooth_v_factor = 2.5):\n",
        "  '''\n",
        "  pytesseract_config: Pytesseract OCR config argument. String.\n",
        "  Default = \"--psm 4\";\n",
        "  conf_thresh: Minimum confidence value for thresholding OCR results. Positive\n",
        "  integer. Default = 0;\n",
        "  h_padding: Horizontal padding on table vertical borders. Positive integer.\n",
        "  Default = 10;\n",
        "  v_padding: Vertical padding on table vertical borders. Positive integer.\n",
        "  Default = 10;\n",
        "  v_distance_threshold: Vertical lines clustering distance threshold.\n",
        "  Default = 3;\n",
        "  h_distance_threshold: Horizontal lines clustering distance threshold.\n",
        "  Default = 15;\n",
        "  v_cluster_threshold: Vertical lines clustering threshold. Determines the\n",
        "  minimum amount of elements to form an x coordinate cluster. Default = 10;\n",
        "  smooth_v_factor: Smoothening factor for vertical lines. Positive integer.\n",
        "  Default = 2.5;\n",
        "  '''\n",
        "\n",
        "  # Pytesseract image_to_data method on input image\n",
        "  OCRdict = pytesseract.image_to_data(image,\n",
        "                                      lang = 'eng',\n",
        "                                      output_type = pytesseract.Output.DICT,\n",
        "                                      config = pytesseract_config)\n",
        "  \n",
        "  # Initializing coords, gaps, and OCR text list\n",
        "  coords = []\n",
        "  h_gaps = []\n",
        "  v_gaps = []\n",
        "  OCRtext = []\n",
        "  confs = []\n",
        "\n",
        "  for i in range(0, len(OCRdict[\"text\"])):\n",
        "    # Retrieving current text and coordinates\n",
        "    x0 = OCRdict[\"left\"][i]\n",
        "    y0 = OCRdict[\"top\"][i]\n",
        "    w0 = OCRdict[\"width\"][i]\n",
        "    h0 = OCRdict[\"height\"][i]\n",
        "    text0 = OCRdict[\"text\"][i]\n",
        "    conf0 = OCRdict[\"conf\"][i]\n",
        "\n",
        "    # Retrieving following text and coordinates\n",
        "    try:\n",
        "      x1 = OCRdict[\"left\"][i+1]\n",
        "      y1 = OCRdict[\"top\"][i+1]\n",
        "      w1 = OCRdict[\"width\"][i+1]\n",
        "      h1 = OCRdict[\"height\"][i+1]\n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "    # Calculating vertical and horizontal gaps\n",
        "    h_gap = x1 - (x0 + w0)\n",
        "    v_gap = y1 - (y0 + h0)\n",
        "\n",
        "    if (conf0 > conf_thresh) and (h0 < image.shape[0]/2) and (w0 < image.shape[1]/2):\n",
        "      coords.append((x0, y0, w0, h0))\n",
        "      h_gaps.append(h_gap)\n",
        "      v_gaps.append(v_gap)\n",
        "      OCRtext.append(text0)\n",
        "      confs.append(conf0)\n",
        "\n",
        "  # Clustering x coordinates to determine vertical lines\n",
        "  x_coords = [(x[0], 0) for x in coords]\n",
        "\n",
        "  # Hierarchical clustering - vertical lines\n",
        "  clustering = AgglomerativeClustering(n_clusters = None,\n",
        "                                      affinity = \"manhattan\",\n",
        "                                      linkage = \"complete\",\n",
        "                                      distance_threshold = h_distance_threshold)\n",
        "  clustering.fit(x_coords)\n",
        "\n",
        "  # Initializing vertical lines list\n",
        "  v_lines = []\n",
        "\n",
        "  for cluster in np.unique(clustering.labels_):\n",
        "    ids = np.where(clustering.labels_ == cluster)[0]\n",
        "    \n",
        "    if len(ids) > v_cluster_threshold:\n",
        "      avg_x = np.average([coords[i][0] for i in ids])\n",
        "      v_lines.append(int(avg_x) - h_padding)\n",
        "\n",
        "  v_lines.sort()\n",
        "  n_columns = len(v_lines) # Number of columns defined by vertical lines\n",
        "\n",
        "  # Hierarchical clustering - horizontal lines\n",
        "  y_coords = [(0, y[1]) for y in coords]\n",
        "\n",
        "  clustering = AgglomerativeClustering(n_clusters = None,\n",
        "                                      affinity = \"manhattan\",\n",
        "                                      linkage = \"complete\",\n",
        "                                      distance_threshold = v_distance_threshold)\n",
        "  clustering.fit(y_coords)\n",
        "\n",
        "  # Initializing horizontal lines list\n",
        "  h_lines = []\n",
        "\n",
        "  for cluster in np.unique(clustering.labels_):\n",
        "    ids = np.where(clustering.labels_ == cluster)[0]\n",
        "    # Thresholding on clusters that have at least half of columns populated\n",
        "    # rounded up\n",
        "    if len(ids) > (int(n_columns / 2) + 1):\n",
        "      avg_y = np.average([coords[i][1] for i in ids])\n",
        "      h_lines.append(int(avg_y) - v_padding)\n",
        "\n",
        "  h_lines.sort()\n",
        "\n",
        "  # Calculating vertical gaps and log of vertical gaps defined by vertical lines\n",
        "  lines_v_gaps = [h_lines[i+1] - h_lines[i] for i in range(len(h_lines) - 1)]\n",
        "  log_lines_v_gaps = np.log(lines_v_gaps)\n",
        "\n",
        "  # Vertical gaps smoothening factor\n",
        "  stdev_v_gaps = stdev(log_lines_v_gaps) # Standard deviation of vertical gaps\n",
        "  mean_v_gaps = mean(log_lines_v_gaps) # Mean of vertical gaps\n",
        "\n",
        "  # Vertical gaps smoothened increment and interval\n",
        "  smooth_v_increment = smooth_v_factor * (stdev_v_gaps / np.sqrt(len(lines_v_gaps)))\n",
        "  smooth_v_interval = (mean_v_gaps - smooth_v_increment, mean_v_gaps + smooth_v_increment)\n",
        "\n",
        "  # Converting back to original scale\n",
        "  smooth_v_interval = np.exp(smooth_v_interval).astype(\"int8\")\n",
        "\n",
        "  # Converting to a range interval\n",
        "  smooth_v_interval = range(smooth_v_interval[0], smooth_v_interval[1])\n",
        "\n",
        "  # Updating horizontal lines based on smoothened vertical interval\n",
        "  smooth_h_lines = []\n",
        "  for i, line in enumerate(h_lines):\n",
        "    try:\n",
        "      # Looking forward for at least 2 gaps in a row within smoothened interval\n",
        "      if h_lines[i+2] - h_lines[i+1] in smooth_v_interval:\n",
        "        if h_lines[i+1] - h_lines[i] in smooth_v_interval:\n",
        "          smooth_h_lines.append(line)\n",
        "      # Looking backward for at least 2 gaps in a row within smoothened interval\n",
        "      elif h_lines[i-1] - h_lines[i-2] in smooth_v_interval:\n",
        "        if h_lines[i] - h_lines[i-1] in smooth_v_interval:\n",
        "          smooth_h_lines.append(line)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  # Defining external borders\n",
        "  # Calculating mean vertical spacing within table\n",
        "  v_spacings = []\n",
        "  for i in range(0, len(smooth_h_lines) - 1):\n",
        "    v_spacings.append(smooth_h_lines[i+1] - smooth_h_lines[i])\n",
        "\n",
        "  v_spacing = int(mean(v_spacings) - mean([h[3] for h in coords]))\n",
        "\n",
        "  # Iterating through last column elements to determine last column max width\n",
        "  last_column_widths = []\n",
        "  for id in np.where([x[0] for x in coords] > np.max(v_lines))[0]:\n",
        "    last_column_widths.append(coords[id][2])\n",
        "\n",
        "  # Last column max width with padding\n",
        "  last_column_width = np.max(last_column_widths) + 2 * h_padding\n",
        "\n",
        "  # Final table dimensions\n",
        "  n_rows = len(smooth_h_lines)\n",
        "  n_columns = len(v_lines)\n",
        "  table_dim = (n_rows, n_columns)\n",
        "\n",
        "  # Redefining preprocessed image as a colored cv2 image\n",
        "  try:\n",
        "    color_preprocessed = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "  except:\n",
        "    color_preprocessed = image\n",
        "\n",
        "  # Borders and lines colors\n",
        "  border_color = [51, 102, 0] # dark green\n",
        "  lines_color = [76, 153, 0] # mild pale green\n",
        "\n",
        "  # Table corners\n",
        "  x_min = np.min(v_lines)\n",
        "  y_min = np.min(smooth_h_lines)\n",
        "  x_max = np.max(v_lines) + last_column_width\n",
        "  y_max = np.max(smooth_h_lines) + v_spacing + v_padding\n",
        "\n",
        "  # Drawing external borders\n",
        "  cv2.rectangle(color_preprocessed,\n",
        "                (x_min, y_min),\n",
        "                (x_max, y_max),\n",
        "                color = border_color,\n",
        "                thickness = 3)\n",
        "\n",
        "  for v_line in v_lines:\n",
        "    if v_line != x_min:\n",
        "      cv2.line(color_preprocessed,\n",
        "              (v_line, y_min),\n",
        "              (v_line, y_max),\n",
        "              color = lines_color,\n",
        "              thickness = 2)\n",
        "      \n",
        "  for h_line in smooth_h_lines:\n",
        "    if h_line != y_min:\n",
        "      cv2.line(color_preprocessed,\n",
        "              (x_min, h_line),\n",
        "              (x_max, h_line),\n",
        "              color = lines_color,\n",
        "              thickness = 2)\n",
        "\n",
        "  # Columns ranges\n",
        "  columns = []\n",
        "  for i in range(0, len(v_lines) -1):\n",
        "    columns.append(range(v_lines[i], v_lines[i+1]))\n",
        "\n",
        "  # Appending last column\n",
        "  columns.append(range(v_lines[-1], x_max))\n",
        "\n",
        "  # Rows ranges\n",
        "  rows = []\n",
        "  for i in range(0, len(smooth_h_lines) -1):\n",
        "    rows.append(range(smooth_h_lines[i], smooth_h_lines[i+1]))\n",
        "\n",
        "  # Appending last row\n",
        "  rows.append(range(smooth_h_lines[-1], y_max))\n",
        "\n",
        "  # Initializing empty table to store text\n",
        "  table = np.empty(table_dim, dtype = 'object')\n",
        "\n",
        "  # Iterating through OCR text and storing values on initialized table\n",
        "  for coord, text in zip(coords, OCRtext):\n",
        "    for j in range(0, len(columns)):\n",
        "      for i in range(0, len(rows)):\n",
        "        if (int(coord[0] + coord[2]/2) in columns[j]) and (int(coord[1] + coord[3]/2) in rows[i]):\n",
        "          if table[i, j] is not None:\n",
        "            table[i, j] += f\" {text}\"\n",
        "          else:\n",
        "            table[i, j] = text\n",
        "\n",
        "  df = pd.DataFrame(table[1:], columns = table[0])\n",
        "\n",
        "  table = {}\n",
        "  table['coords'] = coords\n",
        "  table['OCRtext'] = OCRtext\n",
        "  table['confs'] = confs\n",
        "  table['image'] = color_preprocessed\n",
        "  table['df'] = df\n",
        "\n",
        "  return table"
      ],
      "metadata": {
        "id": "e2xgp3mIg1zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing parameters\n",
        "preprocess_args = {\n",
        "        \"resize\": 1000,\n",
        "        \"grayscale\": True,\n",
        "        \"thresholding\": \"binary\",\n",
        "        \"thresh_value\": 165\n",
        "}\n",
        "\n",
        "# OCR table extraction parameters\n",
        "draw_table_args = {\n",
        "    \"pytesseract_config\": \"--psm 4\",\n",
        "    \"h_padding\": 10,\n",
        "    \"v_padding\": 10,\n",
        "    \"h_distance_threshold\": 3,\n",
        "    \"v_distance_threshold\": 25,\n",
        "    \"smooth_v_factor\": 3\n",
        "}"
      ],
      "metadata": {
        "id": "G0v-3TpKh5ei"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting table for images on input folder\n",
        "tables = {}\n",
        "\n",
        "for image in tqdm(images):\n",
        "  match = re.search(\"[A-Z][a-z]*.[0-9][0-9][0-9][0-9]\", image)\n",
        "  if match is not None:\n",
        "    table_name = match.group(0).replace(\"-\", \"_\")\n",
        "    preprocessed = preprocess(image, **preprocess_args, verbose = False)\n",
        "    tables[table_name] = draw_table(preprocessed, **draw_table_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zcf_tXNAHeV",
        "outputId": "0541bd24-c500-4798-c1b6-0b904c10f960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [06:15<00:00,  9.38s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Writting png and csv files\n",
        "for table in tables:\n",
        "  cv2.imwrite(f\"output/png/{str(table)}.png\", tables[table]['image'])\n",
        "  tables[table]['df'].to_csv(f\"output/csv/{str(table)}.csv\")\n",
        "\n",
        "# Creating output zip folder\n",
        "shutil.make_archive(\"output\", \"zip\", 'output/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tlcdBw9fS_62",
        "outputId": "c60e32d0-a8b1-47a8-8ec3-70e37d72abfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}